{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live Emotion Detection</title>
    <link rel="stylesheet" href="{% static 'css/styles.css' %}">
    <style>
        /* Add some basic styling */
        .container {
            text-align: center;
            margin: 20px;
        }
        #emotionDisplay {
            margin-top: 20px;
            font-size: 20px;
            font-weight: bold;
        }
        #songList {
            margin-top: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Live Emotion Detection</h1>
        <video id="video" width="340" height="300" autoplay></video>
        <div>
            <button id="startDetection">Start Detection</button>
            <button id="stopDetection">Stop Detection</button>
        </div>
        <div id="emotionDisplay"></div>
        <div id="songList"></div>
    </div>

    <script>
        const video = document.getElementById('video');
        const songList = document.getElementById('songList');
        const emotionDisplay = document.getElementById('emotionDisplay');
    
        // Access the camera
        navigator.mediaDevices.getUserMedia({ video: true })
            .then(stream => {
                video.srcObject = stream;
            })
            .catch(err => {
                console.error("Error accessing camera: ", err);
            });
    
        document.getElementById('startDetection').addEventListener('click', () => {
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const context = canvas.getContext('2d');
    
            // Function to send the image and process response
            const sendImageForEmotionDetection = () => {
                context.drawImage(video, 0, 0, canvas.width, canvas.height);
    
                // Send image data to the backend for emotion detection
                canvas.toBlob(blob => {
                    const formData = new FormData();
                    formData.append('image', blob, 'capture.jpg');
    
                    fetch('/detect-emotion/', {
                        method: 'POST',
                        body: formData,
                        headers: {
                            'X-CSRFToken': '{{ csrf_token }}'  // Ensure this is rendered correctly
                        }
                    })
                    .then(response => {
                        if (!response.ok) {
                            console.error('Network response was not ok:', response);
                            throw new Error('Network response was not ok');
                        }
                        return response.json();
                    })
                    .then(data => {
                        console.log('Received data:', data); // Debugging log
                        // Display detected emotion
                        if (data.emotion) {
                            emotionDisplay.innerHTML = `Detected Emotion: ${data.emotion}`;
                        } else {
                            console.error('Emotion not found in response:', data);
                            emotionDisplay.innerHTML = 'Emotion not detected.';
                        }
    
                        // Clear previous song list
                        songList.innerHTML = '';
    
                        // Check if song_links exist in the response
                        if (data.song_links) {
                            data.song_links.forEach(song_id => {
                                const iframe = document.createElement('iframe');
                                iframe.style.borderRadius = '20px';
                                iframe.style.marginBottom = '10px';
                                iframe.src = `https://open.spotify.com/embed/track/${song_id}?utm_source=generator&autoplay=1`;
                                iframe.height="180";
                                iframe.width="900";
                                iframe.allowFullscreen = true;
                                iframe.allow = "autoplay; encrypted-media";  // Ensure autoplay is allowed
                                iframe.style.border = 'none';  // Remove outline box
                                songList.appendChild(iframe);
                            });
                        } else {
                            console.error('No song links returned:', data);
                            songList.innerHTML = 'No songs available for this emotion.';
                        }
                    })
                    .catch(error => {
                        console.error('Error fetching data:', error);
                    });
                });
            };
    
            // Send the first image immediately
            sendImageForEmotionDetection();
    
            // Capture and send image every 3 minutes (180,000 milliseconds)
            const intervalId = setInterval(sendImageForEmotionDetection, 180000); // 180000 milliseconds = 3 minutes
    
            // Optional: Stop detection button
            document.getElementById('stopDetection').addEventListener('click', () => {
                clearInterval(intervalId);
                video.srcObject.getTracks().forEach(track => track.stop()); // Stop the video stream
                emotionDisplay.innerHTML = 'Detection stopped.';
            });
        });
    </script>
    
    
</body>
</html>
